# -*- coding: utf-8 -*-
"""TachiBranco_SimuladorV2.ipynb

Automatically generated by Colab.

# Import Bibliotecas
"""

# Importando bibliotecas padrão

from tqdm import tqdm
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib as mpl
from numpy import sqrt
from numpy import argmax
from imblearn.over_sampling import RandomOverSampler
from datetime import datetime as dt
from scipy import stats
from warnings import simplefilter
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn import linear_model
from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from datetime import datetime as dt
from tqdm import tqdm
import tzlocal
import datetime
import statsmodels.api as sm
import math as m
import random
#!pip install pycaret
#from pycaret.classification import *

from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV
from sklearn.metrics import classification_report, precision_score, precision_recall_fscore_support, make_scorer
from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error, confusion_matrix
#from mlxtend.evaluate import bias_variance_decomp

import warnings
warnings.filterwarnings('ignore')
simplefilter(action='ignore', category=FutureWarning)
plt.rc("font", size=14)
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

from google.colab import drive
drive.mount('/content/drive')

"""# Import Dados"""

# Importando os dados da planilha Local
#df_arvores = pd.read_excel('C:/Users/Pablo Henrique/Google Drive/Masters/Dissertacao/Dados/Dados_Tachi.xlsx', 'dados_arvores')
#df_arvores.head()

#df_parcelas = pd.read_excel('C:/Users/Pablo Henrique/Google Drive/Masters/Dissertacao/Dados/Dados_Tachi.xlsx', 'dados_parcela')
#df_parcelas.head()

# Importando os dados da planilha Google Colab
df_arvores = pd.read_excel('/content/drive/Othercomputers/Notebook Pessoal/Google Drive/Masters/Dissertacao/Dados/Dados_Tachi.xlsx', 'dados_arvores')
df_parcelas = pd.read_excel('/content/drive/Othercomputers/Notebook Pessoal/Google Drive/Masters/Dissertacao/Dados/Dados_Tachi.xlsx', 'dados_parcela')

df_arvores.head()

"""#Functions

## Feature Engineering

### Índices de Competição
"""

def calc_indices_competicao(df):
    """Função que calcula as medidas méidas da parcela e cria os índices de competitividade"""

    #Calcula as médias da parcela
    df_avg_parc = df.groupby(['Bloco-Trat', 'N_Medicao']).agg({'Deq_cm':'mean', 'HtArv_m':'mean'}).reset_index()
    df_avg_parc.rename(columns={'Deq_cm':'media_deq', 'HtArv_m':'media_alt'}, inplace=True)
    #Join Medias
    df_merge_avg = pd.merge(df, df_avg_parc, how='inner', on=['Bloco-Trat','N_Medicao'])

    #IID1 (dap)
    df_merge_avg['iid1'] = (df_merge_avg['Deq_cm']**2) / (df_merge_avg['media_deq']**2)

    #IID2 (alt)
    df_merge_avg['iid2'] = df_merge_avg['HtArv_m']/df_merge_avg['media_alt']

    #IID3 (dap e alt)
    df_merge_avg['iid3'] = ((df_merge_avg['Deq_cm']**2)*df_merge_avg['HtArv_m']) / ((df_merge_avg['media_deq']**2)*df_merge_avg['media_alt'])
    return df_merge_avg

"""### Medidas t+1"""

def calcula_medidas_t1(df):
  """Função para calcular as medidas das árvores no tempo t+1"""

  #Aninhando medicoes originais e t+1
  df_arv_future = df.loc[df['N_Medicao']>1]
  df_arv_future['N_Medicao'] = df_arv_future['N_Medicao']-1
  df_arv_future = df_arv_future[['Bloco-Trat_cod-Arv','N_Medicao','Deq_cm','HtArv_m','ArvViva','Idade_anos']]

  #Join entre base original e base futura t+1
  df_arvores_ref3 = pd.merge(df, df_arv_future, how='left', on=['Bloco-Trat_cod-Arv','N_Medicao'])

  #Renomeando colunas
  df_arvores_ref3.rename(columns={'Deq_cm_y':'Deq_cm_t1',
                                  'HtArv_m_y':'HtArv_m_t1',
                                  'ArvViva_y':'ArvViva_t1',
                                  'Idade_anos_y': 'Idade_anos_t1',
                                  'Deq_cm_x':'Deq_cm',
                                  'HtArv_m_x':'HtArv_m',
                                  'ArvViva_x':'ArvViva',
                                  'Idade_anos_x': 'Idade_anos'}
                        , inplace=True)

  #Criando id-tree
  df_arvores_ref3['id_tree'] = df_arvores_ref3['Bloco-Trat_cod-Arv']

  #Ordenando DataFrame de saída
  df_arvores_ref3 = df_arvores_ref3.sort_values(by=['id_tree','N_Medicao'])

  return df_arvores_ref3

"""### Taxas de Crescimento t+1

#### Calculo limites
"""

def calculo_limitex_tx_cresc(df):
  """Função para calcular os limites da taxa de crescimento"""

  #Cálculos crescimento
  df['TxCrescMensal_Deq'] = ((df['Deq_cm_t1']/df['Deq_cm'])-1)/(df['Idade_anos_t1']-df['Idade_anos'])
  df['TxCrescMensal_Ht'] = ((df['HtArv_m_t1']/df['HtArv_m'])-1)/(df['Idade_anos_t1']-df['Idade_anos'])

  #Calcula medidas das variáveis
  df_summ_tx = df \
    .groupby(['N_Medicao']) \
    .agg(
        media_Ht=('TxCrescMensal_Ht', 'mean'),
        desviopad_Ht=('TxCrescMensal_Ht', 'std'),
        media_Deq=('TxCrescMensal_Deq', 'mean'),
        desviopad_Deq=('TxCrescMensal_Deq', 'std'),
        media_real_Deq=('Deq_cm', 'mean'),
        media_real_Ht=('HtArv_m', 'mean')
        )

  df_summ_tx_ii = df_summ_tx.reset_index()

  #Define Taxa de Crescimento máxima
  df_summ_tx_ii['LimiteTxCrescHt'] = 1+(df_summ_tx_ii['media_Ht']+1.5*df_summ_tx_ii['desviopad_Ht'])
  df_summ_tx_ii['LimiteTxCrescDeq'] = 1+(df_summ_tx_ii['media_Deq']+1.5*df_summ_tx_ii['desviopad_Deq'])

  df_limite_tx_cresc = df_summ_tx_ii[['N_Medicao','LimiteTxCrescHt','LimiteTxCrescDeq']]

  return df_limite_tx_cresc

"""#### Aplicação Limitador Tx Cresc"""

#Função para limitar a taxa de crescimento
def limitador_tx_cresc(df, df_limite, column_atual, column_futuro, tipo_limite):
  df['taxa_predita'] = df[column_futuro]/df[column_atual]
  df_manip = pd.merge(df, df_limite, how='inner', on='N_Medicao')
  df_manip[column_futuro] = np.where(df_manip['taxa_predita'] > df_manip[tipo_limite], df_manip[column_atual]*df_manip[tipo_limite], df_manip[column_futuro])

  return df_manip[column_futuro]

"""## Modelo Crescimento | Regressão linear"""

# Function Cálculo Métricas
def metricas_modelo_rl(model, x_test, x_train, y_train, y_test):
    from sklearn import linear_model, metrics

    #Teste do modelo
    y_predict = model.predict(x_test)
    y_predict_train = model.predict(x_train)

    #Calculo Métricas avaliação modelo
    r2 = metrics.r2_score(y_train, y_predict_train)
    r2_pred_obs = metrics.r2_score(y_test,y_predict)
    rmse = sqrt(metrics.mean_squared_error(y_train, y_predict_train))
    mae = metrics.mean_absolute_error(y_train, y_predict_train)

    return r2, r2_pred_obs, rmse, mae

def treinamento_reg_lin(df, target):

  """Modelo treinado utilizando IID3 e Intercepto"""

  df_model_ht = df.loc[df.ArvViva_t1 == 1]
  df_model_ht = df_model_ht.dropna()
  x_ht = df_model_ht[['Espacamento','Idade_Mes','N_FusteVivo','Deq_cm','HtArv_m','iid3']]
  y_ht = df_model_ht[target]
  #x_ht = sm.add_constant(x_ht)

  #Criando os datasets de treino e teste
  x_train, x_test, y_train, y_test = train_test_split(x_ht, y_ht, test_size=0.2, random_state=9)

  #Treinamento do Modelo
  est = sm.OLS(y_train, x_train)
  model = est.fit()
  #print(model.summary())
  model_lr = LinearRegression(fit_intercept=False).fit(x_train, y_train)
  coeficientes_rlin = model_lr.coef_

  return x_train, x_test, y_train, y_test, model, model_lr, coeficientes_rlin

#Plot Predict x Realizado
#y_predict = model.predict(x_test)
#plt.plot(y_test, y_predict, 'o')

"""## Modelo Mortalidade | Reg Logística

### Modelo treinado - Manual
"""

def treinamento_reg_log_manual(df):
  #Criando os datasets de treino e teste
  df_model_mrt = df[['ArvViva_t1','Espacamento','Idade_Mes','N_FusteVivo','Deq_cm','HtArv_m','iid3']].dropna()
  x = df_model_mrt[['Espacamento','Idade_Mes','N_FusteVivo','Deq_cm','HtArv_m','iid3']]
  y = df_model_mrt[['ArvViva_t1']]

  #Aplicando Oversampling para balancear variáveis
  oversample = RandomOverSampler(sampling_strategy='minority')
  x_over, y_over = oversample.fit_resample(x, y)

  x_train, x_test, y_train, y_test = train_test_split(x_over, y_over, test_size=0.2, shuffle=True, random_state=9)

  #Iniciando o modelo com os parâmetros
  clf_log = LogisticRegression(C=1,
                              solver='lbfgs',
                              max_iter=1000,
                              multi_class='auto',
                              class_weight=None,
                              fit_intercept=True,
                              )

  #Fit do modelo e calculo métricas
  model_logit = clf_log.fit(x_train, y_train)

  #Tabela com as probabilidades calculadas
  y_pred_class = pd.DataFrame(clf_log.predict(x_test)).rename(columns = {0: 'F_predict'})
  y_pred_prob = clf_log.predict_proba(x_test)

  #Acurácia e ROC AUC Score
  acc_log = clf_log.score(x_test, y_test)
  auc = roc_auc_score(y_test, y_pred_class)

  #Coeficientes
  coeficientes_rlog = clf_log.coef_

  return x_train, x_test, y_train, y_test, y_pred_class, y_pred_prob, coeficientes_rlog, acc_log, auc, clf_log


def simulador_ac_model(df_orig, parc_sim, num_t, coefs_Alt, coefs_Deq, coefs_mort, df_limite_tx_cresc):

    #Inicialização
    n=0
    df = df_orig.loc[(df_orig['Bloco-Trat']==parc_sim) & (df_orig['N_Medicao']==1)]
    stories = []
    stories = pd.DataFrame(stories)

    for n in tqdm(range(1,num_t)):

        df3 = df.copy()
        df3 = df3.reset_index()

        ##################
        ## CALCULO VTCC ##
        ##################
        df3['Vtcc_Arv_m3_Schuma'] = np.exp(-9.164635 + 1.912123*np.log(df3['Deq_cm']) + 0.751405*np.log(df3['HtArv_m']))

        ########################
        ## REGRESSÕES MEDIDAS ##
        ########################

        df3['Deq_cm_futuro'] = coefs_Deq[0]*df3['Espacamento'] + coefs_Deq[1]*df3['Idade_Mes'] + coefs_Deq[2]*df3['N_FusteVivo'] + coefs_Deq[3]*df3['Deq_cm'] + coefs_Deq[4]*df3['HtArv_m'] + coefs_Deq[5]*df3['iid3']
        df3['Deq_cm_futuro'] = limitador_tx_cresc(df3, df_limite_tx_cresc, 'Deq_cm', 'Deq_cm_futuro', 'LimiteTxCrescDeq')

        df3['HtArv_m_futuro'] = coefs_Alt[0]*df3['Espacamento'] + coefs_Alt[1]*df3['Idade_Mes'] + coefs_Alt[2]*df3['N_FusteVivo'] + coefs_Alt[3]*df3['Deq_cm'] + coefs_Alt[4]*df3['HtArv_m'] + coefs_Alt[5]*df3['iid3']
        df3['HtArv_m_futuro'] = limitador_tx_cresc(df3, df_limite_tx_cresc, 'HtArv_m', 'HtArv_m_futuro', 'LimiteTxCrescHt')

        ###########################
        ## REGRESSÃO MORTALIDADE ##
        ###########################

        #Regressao Logistica original
        result_calc_coefs = (coefs_mort[0][0]*df3['Espacamento'] + coefs_mort[0][1]*df3['Idade_Mes'] + coefs_mort[0][2]*df3['N_FusteVivo'] + coefs_mort[0][3]*df3['Deq_cm'] + coefs_mort[0][4]*df3['HtArv_m'] + coefs_mort[0][5]*df3['iid3'])
        df3['prob_morte'] = 100*((np.exp(result_calc_coefs))/(1 + np.exp(result_calc_coefs)))
        df3 = df3.round(4)

        #Define classificação baseada no número aleatório
        list_random = []
        for i in range(0,len(df3)):
            rn = random.randint(0,100)
            list_random.append(rn)

        df_list_random = pd.DataFrame(list_random)
        df4 = pd.merge(df3.reset_index(), df_list_random, how='inner', left_index=True, right_index=True)
        df4.rename(columns={0: 'random_n'}, inplace=True)
        df_debug = df4
        df4['estado_futuro'] = np.where(df4['random_n']>(df4['prob_morte']), 0, 1)

        df4['HtArv_m_futuro'] = df4['HtArv_m_futuro']*df4['estado_futuro']
        df4['Deq_cm_futuro'] = df4['Deq_cm_futuro']*df4['estado_futuro']

        ###########################
        ## ATUALIZAÇÃO DATAFRAME ##
        ###########################
        df_update = df4[['id_tree','x_loc','y_loc','Espacamento','N_FusteVivo','Deq_cm_futuro','HtArv_m_futuro','Vtcc_Arv_m3_Schuma','iid3','N_Medicao','Idade_Mes','Bloco-Trat']].loc[df4['estado_futuro']==1]
        df_update['N_Medicao'] = n+1
        df_update = df_update.rename(columns={'HtArv_m_futuro':'HtArv_m', 'Deq_cm_futuro':'Deq_cm'})
        stories = pd.concat([stories,df4])
        df = df_update.copy()

    return stories


"""### Resultados simulação"""

def calculo_erro(df_orig, parc_sim, stories):

    df_orig_teste = df_orig.loc[(df_orig['Bloco-Trat']==parc_sim)]
    df_orig_teste = df_orig_teste.dropna()

    df_real = df_orig_teste.groupby(['Bloco-Trat', 'N_Medicao','Espacamento','N_FusteVivo']).agg({
        'Vtcc_Arv_m3_Schuma':'sum',
        'id_tree':pd.Series.nunique,
        'HtArv_m':'mean',
        'Deq_cm':'mean'
        }).reset_index()

    df_pred = stories.groupby(['Bloco-Trat', 'N_Medicao', 'Espacamento','N_FusteVivo']).agg({
        'Vtcc_Arv_m3_Schuma':'sum',
        'id_tree':pd.Series.nunique,
        'HtArv_m':'mean',
        'Deq_cm':'mean'
        }).reset_index()

    df_metrics = pd.merge(df_real, df_pred, how='inner', on=['Bloco-Trat','N_Medicao', 'Espacamento', 'N_FusteVivo'])

    df_metrics.rename(columns={
        'Vtcc_Arv_m3_Schuma_x':'VolumeTotalReal',
        'Vtcc_Arv_m3_Schuma_y':'VolumeTotalPredito',
        'id_tree_x':'QtdArvoresReal',
        'id_tree_y':'QtdArvoresPredito',
        'HtArv_m_x':'AlturaMediaReal',
        'HtArv_m_y':'AlturaMediaPredito',
        'Deq_cm_x':'DEQMediaReal',
        'Deq_cm_y':'DEQMediaPredito',
        }, inplace=True)

    df_metrics['%ErroEstimação_Volume'] = round(((df_metrics['VolumeTotalReal']/df_metrics['VolumeTotalPredito'])-1)*100, 2)
    df_metrics['%ErroEstimação_QtdArvores'] = round(((df_metrics['QtdArvoresReal']/df_metrics['QtdArvoresPredito'])-1)*100, 2)

    return df_metrics

def apresenta_resultados(df_simulation, list_groupby):
  df_mean_error = df_simulation \
                    .groupby(['Bloco-Trat','N_Medicao', 'Espacamento','N_FusteVivo']) \
                    .mean('%ErroEstimação') \
                    .reset_index()

  df_resultado_geral = df_mean_error \
    .groupby(list_groupby) \
    .agg({'%ErroEstimação_Volume':'mean',
          '%ErroEstimação_QtdArvores':'mean',
          'AlturaMediaReal':'mean',
          'AlturaMediaPredito':'mean',
          'DEQMediaReal':'mean',
          'DEQMediaPredito':'mean',
          'VolumeTotalReal':'mean',
          'VolumeTotalPredito':'mean',
          'QtdArvoresReal':'mean',
          'QtdArvoresPredito':'mean',
        })

  return df_resultado_geral

"""#Exe Simulador Completo"""

#Data Preparation
df_sim1 = calc_indices_competicao(df_arvores)
df_sim2 = calcula_medidas_t1(df_sim1)
df_limite_tx_cresc = calculo_limitex_tx_cresc(df_sim2)

list_parcelas = (df_sim2['Bloco-Trat'].drop_duplicates()).to_list()

#Define quantidade de simulações
num_sims = 10
hist_summ_resultados_sim = []
hist_summ_resultados_sim = pd.DataFrame(hist_summ_resultados_sim)

for i in range(0,num_sims):

  #Split parcelas para base de dados em 80/20
  parcelas_sim_ac = random.sample(list_parcelas, 4)
  parcelas_modelos = [parcela for parcela in list_parcelas if parcela not in parcelas_sim_ac]

  #Modelos = Simulador
  #parcelas_modelos = parcelas_sim_ac

  df_train_models = df_sim2.loc[df_sim2['Bloco-Trat'].isin(parcelas_modelos)]
  df_test_ac = df_sim2.loc[df_sim2['Bloco-Trat'].isin(parcelas_sim_ac)]

  #Treinamento dos Modelos
  x_train_alt, x_test_alt, y_train_alt, y_test_alt, model_alt, model_lr_alt, coeficientes_rlin_alt = treinamento_reg_lin(df_train_models, 'HtArv_m_t1')
  r2_deq, r2_pred_obs_alt, rmse, mae = metricas_modelo_rl(model_alt, x_test_alt, x_train_alt, y_train_alt, y_test_alt)

  x_train_deq, x_test_deq, y_train_deq, y_test_deq, model_deq, model_lr_deq, coeficientes_rlin_deq = treinamento_reg_lin(df_train_models, 'Deq_cm_t1')
  r2_alt, r2_pred_obs_alt, rmse, mae = metricas_modelo_rl(model_deq, x_test_deq, x_train_deq, y_train_deq, y_test_deq)

  x_train_mort, x_test_mort, y_train_mort, y_test_mort, y_pred_class_mort, y_pred_prob_mort, coeficientes_rlog_mort, acc_log, auc, clf_log = treinamento_reg_log_manual(df_train_models)

  #df_train, df_test, best_model = treinamento_reg_log_pycaret(df_train_models)

  #Simulador AC
  df_simulation = []
  df_simulation = pd.DataFrame(df_simulation)
  num_t = 8

  df_simulador = df_test_ac[['id_tree','x_loc','y_loc','Espacamento','N_FusteVivo','Deq_cm','HtArv_m','Vtcc_Arv_m3_Schuma','media_deq','media_alt','iid3','N_Medicao','Idade_Mes','Bloco-Trat']]
  for parc_sim in parcelas_sim_ac:

    #Simulador Modelo Manual
    stories = simulador_ac_model(df_simulador, parc_sim, num_t, coeficientes_rlin_alt, coeficientes_rlin_deq, coeficientes_rlog_mort, df_limite_tx_cresc)

    #Simulador Modelo PyCaret
    #stories = simulador_ac_pycaret(df_simulador, parc_sim, num_t, coeficientes_rlin_alt, coeficientes_rlin_deq, best_model, df_limite_tx_cresc)

    df_erro = calculo_erro(df_simulador, parc_sim, stories)

    df_simulation = pd.concat([df_simulation, df_erro])

  #Apresenta Resultados
  list_groupby = ['N_Medicao', 'Espacamento'] ##Define GroupBy dos Resultados
  summary_resultado_sim = apresenta_resultados(df_simulation, list_groupby).reset_index()

  summary_resultado_sim['Id_simulacao'] = i
  summary_resultado_sim['r2_reglin_alt'] = r2_alt
  summary_resultado_sim['r2_reglin_deq'] = r2_deq
  summary_resultado_sim['accuracy_reglog'] = acc_log
  summary_resultado_sim['auc_reglog'] = auc

  hist_summ_resultados_sim = pd.concat([hist_summ_resultados_sim, summary_resultado_sim])

hist_summ_resultados_sim.to_csv('sim_gf.csv', sep=";")